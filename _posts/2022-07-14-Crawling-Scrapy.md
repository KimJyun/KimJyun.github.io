---
title: "[Crawling][Scrapy] ê³µë¶€í•˜ë©° ì •ë¦¬í•˜ê¸° - 01"
excerpt:
categories:
  - Crawling
  - Scrapy

tags:
  - Crawling
  - Scrapy

date: 2022-07-14
last_modified_at: 2022-07-14
---

# [Crawling] Scrapy ì •ë¦¬ 01

## Scrapy í”„ë¡œì íŠ¸ì˜ ê¸°ë³¸ êµ¬ì¡°

```
scrapy.cfg
myproject/
    __init__.py
    items.py
    middlewares.py
    pipelines.py
    settings.py
    spiders/
        __init__.py
        spider1.py
        spider2.py
        ...
```

- í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ : `scrapy.cfg` íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
  > í”„ë¡œì íŠ¸ ì„¤ì •ì„ ì •ì˜í•˜ëŠ” python ëª¨ë“ˆì˜ ì´ë¦„ì´ í¬í•¨ëœë‹¤.

```
[settings]
default = myproject.settings
```

## í”„ë¡œì íŠ¸ ë§Œë“¤ê¸°

```
scrapy startproject <myproject> [project_dir]
```

ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´ `project_dir`ë””ë ‰í† ë¦¬ ì•„ë˜ì— `myproject`ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ scrapy í”„ë¡œì íŠ¸ê°€ ìƒì„±ëœë‹¤.
<br/><br/>
ë‹¤ìŒìœ¼ë¡œ ìƒˆ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•œë‹¤.

```
cd [project_dir]
```

ì—¬ê¸°ì—ì„œ `scrapy`ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ ê´€ë¦¬í•˜ê³  ì œì–´ê°€ ê°€ëŠ¥í•˜ë‹¤.
<br/><br/>

## í”„ë¡œì íŠ¸ ì œì–´

- ìƒˆ spider ë§Œë“¤ê¸°

```
scrapy genspider <name> <domain or URL>
```

### ğŸ“ crawl

```
scrapy crawl <spider>
```

- í”„ë¡œì íŠ¸ í•„ìš”

spiderë¥¼ ì‚¬ìš©í•˜ì—¬ í¬ë¡¤ë§ì„ ì‹œì‘í•œë‹¤.

### ğŸ“ fetch

```
scrapy fetch <url>
```

- í”„ë¡œì íŠ¸ í•„ìš” ì—†ìŒ

Scrapy Downloaderë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ urlì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ë‚´ìš©ì„ í‘œì¤€ ì¶œë ¥ì— ì“´ë‹¤.
<br/><br/>

ì§€ì›ë˜ëŠ” ì˜µì…˜ :

- `spider=SPIDER` : spider ìë™ ê°ì§€ ìš°íšŒ ë° íŠ¹ì • ìŠ¤íŒŒì´ë” ê°•ì œ ì‚¬ìš©
- `--headers` : requestì˜ body ëŒ€ì‹  requestì˜ HTTP Headerë¥¼ ì¶œë ¥
- `no-redirect` : HTTP 3xx redirectsì„ ë”°ë¥´ì§€ ì•ŠìŒ(default : redirects ë”°ë¦„)

ì‚¬ìš© ì˜ˆì‹œ :

```
$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{'Accept-Ranges': ['bytes'],
 'Age': ['1263   '],
 'Connection': ['close     '],
 'Content-Length': ['596'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
 'Etag': ['"573c1-254-48c9c87349680"'],
 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
 'Server': ['Apache/2.2.3 (CentOS)']}
```

### ğŸ“ view

```
scrapy view <url>
```

- í”„ë¡œì íŠ¸ í•„ìš” ì—†ìŒ

Scrapy spider ê°€ ë³´ëŠ” ê²ƒì²˜ëŸ¼ ë¸Œë¼ìš°ì €ì—ì„œ ì£¼ì–´ì§„ URLì„ ì—°ë‹¤. ê°€ë” spiderê°€ ë³´ëŠ” í˜ì´ì§€ê°€ ìš°ë¦¬ê°€ ë³´ëŠ” ê²ƒê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì˜ˆìƒí•œ ë‚´ìš©ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

ì‚¬ìš© ì˜ˆ :

```
$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
```

### ğŸ“ Shell

```
scrapy shell [url]
```

- í”„ë¡œì íŠ¸ í•„ìš” ì—†ìŒ

ì£¼ì–´ì§„ URLì— ëŒ€í•´ Scrapy shellì„ ì‹¤í–‰í•˜ê±°ë‚˜ URLì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°ëŠ” ë¹„ì–´ ìˆë‹¤. <br/>
ë˜í•œ, `./`, `../` ê°™ì€ ì ˆëŒ€ íŒŒì¼ ê²½ë¡œì¸ UNIX ìŠ¤íƒ€ì¼ ì˜ ë¡œì»¬ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì›í•œë‹¤.

ì§€ì›ë˜ëŠ” ì˜µì…˜ :

- `-c code` : shellì—ì„œ ì½”ë“œë¥¼ í‰ê°€í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³  ì¢…ë£Œ

ì‚¬ìš© ì˜ˆ :

```
$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'
(200, 'http://www.example.com/')

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(200, 'http://example.com/')

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')
```

### ğŸ“ Parse

```
scrapy parse <url> [options]
```

- í”„ë¡œì íŠ¸ í•„ìš”

`--callback` ì˜µì…˜ê³¼ í•¨ê»˜ ì „ë‹¬ëœ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì§€ì •ëœ URLì„ ê°€ì ¸ì™€ ì´ë¥¼ ì²˜ë¦¬í•˜ëŠ” spiderë¡œ ë¶„ì„í•œë‹¤.

ì§€ì›ë˜ëŠ” ì˜µì…˜ :

- `--spider==SPIDER` : ìŠ¤íŒŒì´ë” ìë™ ê°ì§€ ìš°íšŒ ë° íŠ¹ì • ìŠ¤íŒŒì´ë” ê°•ì œ ì‚¬ìš©
- `--a NAME=VALUE` : ìŠ¤íŒŒì´ë” ì¸ìˆ˜ ì„¤ì •(ë°˜ë³µ ê°€ëŠ¥)
- `--callback` ë˜ëŠ” `-c` : ì‘ë‹µ êµ¬ë¬¸ ë¶„ì„ì„ ìœ„í•œ ì½œë°±ìœ¼ë¡œ ì‚¬ìš©í•  ìŠ¤íŒŒì´ë” ë©”ì„œë“œ
- `--meta` ë˜ëŠ” `-m` : ì½œë°± ìš”ì²­ì— ì „ë‹¬í•  ì¶”ê°€ ìš”ì²­ ë©”íƒ€. ìœ íš¨í–” JSON ë¬¸ìì—´ì´ì–´ì•¼ í•œë‹¤. ì˜ˆ) `cbkwargs='{"foo":"bar"}'`
- `--cbkwargs` : ì½œë°±ì— ì „ë‹¬ë  ì¶”ê°€ í‚¤ì›Œë“œ ì¸ìˆ˜. ìœ íš¨í•œ JSON ë¬¸ìì—´ì´ì–´ì•¼ í•œë‹¤. ì˜ˆ) `'cbkwargs='{"foo":"bar"}'`
- `--pipelines` : íŒŒì´í”„ë¼ì¸ì„ í†µí•´ í•­ëª©ì„ ì²˜ë¦¬
- `--rules` ë˜ëŠ” `-r` : `CrawlSpider` ì‘ë‹µì„ êµ¬ë¶„ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©í•  ì½œë°±
- `--noitems` : ìŠ¤í¬ë©í•œ í•­ëª©ì„ í‘œì‹œí•˜ì§€ ì•ŠìŒ
- `--nolinks` : ì¶”ì¶œëœ ë§í¬ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŒ
- `--nocolour` : ì¶œë ¥ë¬¼ì„ ì±„ìƒ‰í•˜ê¸° ìœ„í•´ ì•ˆë£Œë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆë¼.
- `--depth` ë˜ëŠ” `-d` : ìš”ì²­ì„ ì¬ê·€ì ìœ¼ë¡œ ë”°ë¼ì•¼ í•˜ëŠ” ê¹Šì´ ìˆ˜ì¤€(default : 1)
- `--verbose` ë˜ëŠ” `-v` : ê° ê¹Šì´ ìˆ˜ì¤€ì— ëŒ€í•œ ì •ë³´ í‘œì‹œ
- `--output` ë˜ëŠ” `-o` : ìŠ¤í¬ë©í•œ í•­ëª©ì„ íŒŒì¼ì— ë¤í”„

ì‚¬ìš© ì˜ˆ :

```
$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

>>> STATUS DEPTH LEVEL 1 <<<
# Scraped Items  ------------------------------------------------------------
[{'name': 'Example item',
 'category': 'Furniture',
 'length': '12 cm'}]

# Requests  -----------------------------------------------------------------
[]
```

### ğŸ“ Runspider

```
scrapy runspider <spider_file.py>
```

- í”„ë¡œì íŠ¸ í•„ìš” ì—†ìŒ

í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ í•„ìš” ì—†ì´ Python íŒŒì¼ì— ìì²´ í¬í•¨ëœ spiderë¥¼ ì‹¤í–‰í•œë‹¤.

ì‚¬ìš© ì˜ˆ :

```
$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
```
